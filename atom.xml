<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Neverland</title>
  
  <subtitle>你是我不愿醒来的梦啊&lt;br&gt;真是柔情一场</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ir1d.cf/"/>
  <updated>2019-07-10T13:13:38.754Z</updated>
  <id>https://ir1d.cf/</id>
  
  <author>
    <name>Ir1d</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>EnlightenGAN: Deep Light Enhancement without Paired Supervision</title>
    <link href="https://ir1d.cf/2019/07/10/EnlightenGAN-Deep-Light-Enhancement-without-Paired-Supervision/"/>
    <id>https://ir1d.cf/2019/07/10/EnlightenGAN-Deep-Light-Enhancement-without-Paired-Supervision/</id>
    <published>2019-07-09T17:14:08.000Z</published>
    <updated>2019-07-10T13:13:38.754Z</updated>
    
    <content type="html"><![CDATA[<ul><li>unpair 的低光照增强</li></ul><p>效果看起来真的很给力.. 别人家的 GAN 啊.. 哭爆了</p><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><h2 id="解决的思路"><a href="#解决的思路" class="headerlink" title="解决的思路"></a>解决的思路</h2><p><img src="https://i.loli.net/2019/07/10/5d25ad4af03fb21526.png" alt="20190710171801.png"></p><p>有一个 self feature preserving loss 挺有意思的，作者表示 perceptual loss 可以保留 content 信息。</p><h2 id="核心知识点"><a href="#核心知识点" class="headerlink" title="核心知识点"></a>核心知识点</h2><p>把 illumination channel 当做 attention..</p><p>先 norm 到 [0,1]，然后再取反（1-i）。</p><p>作者表示这个 attention map 是一种 self-regularization，而不是 learned with supervision..</p><p>这个 attention map 然后就拿来在 unet 右侧的 upsample 的过程中乘到 feature map 上。而且也乘到最后的 output image 上，就相当于是 unet 的输出是图片 <strong>的 residual</strong> 的 R 部分。</p><p>作者用两个 Discriminator ，一个处理 local ，另一个处理 global..</p><p>D 都是 LSGAN + RelativisticGAN + PatchGAN..</p><h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><h2 id="改进（？）"><a href="#改进（？）" class="headerlink" title="改进（？）"></a>改进（？）</h2><p>先不说</p><h2 id="other-comment"><a href="#other-comment" class="headerlink" title="other comment"></a>other comment</h2><p>思路很好，用 improve classification 来衡量 enhance 的效果</p><p>参考中，用 semantic pixel labeling of aerial imagery 的效果来衡量 cross view ground level scene prediction 的效果。</p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;unpair 的低光照增强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;效果看起来真的很给力.. 别人家的 GAN 啊.. 哭爆了&lt;/p&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>Multi-Channel Attention Selection GAN with Cascaded Semantic Guidance for Cross-View Image Translation</title>
    <link href="https://ir1d.cf/2019/07/10/Multi-Channel-Attention-Selection-GAN-with-Cascaded-Semantic-Guidancefor-Cross-View-Image-Translation/"/>
    <id>https://ir1d.cf/2019/07/10/Multi-Channel-Attention-Selection-GAN-with-Cascaded-Semantic-Guidancefor-Cross-View-Image-Translation/</id>
    <published>2019-07-09T17:11:41.000Z</published>
    <updated>2019-07-10T09:17:22.431Z</updated>
    
    <content type="html"><![CDATA[<ul><li>用 semantic 信息来指到生成 cross view 的图片</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>本文解决的问题是两个视角之间的 overlap 比较小。</p><p>之前有一些工作是同时生成 semantic 信息和 image。</p><p>但是训练用的 semantic map 往往比较粗糙（甚至是用一些 pretrain 的分割网络获得的），可能会有一些 misguiding。</p><p>作者表示用一个 single phase 的生成网络并不能很好地捕捉两个视角之间的复杂的场景结构关系。而且 3 channel 的 generation space 可能不足以学到一个关于这样复杂的生成问题的很好地 mapping。</p><h2 id="解决的思路"><a href="#解决的思路" class="headerlink" title="解决的思路"></a>解决的思路</h2><p>文中提出了一种 coarse-to-fine 的两阶段生成思路，然后用 attention 机制选取合适的中间结果来辅助最后的 final output 的质量。</p><h2 id="核心知识点"><a href="#核心知识点" class="headerlink" title="核心知识点"></a>核心知识点</h2><p>本文中也是用预训练的 segmentation 方法来得到 semantic map。</p><p>这个 semantic map 还被用来限制最后的 final output ，求它的 segmentation 并和输入的 map 相比较，相当于是做个 reconstruction 的限制吧。</p><p><img src="https://i.loli.net/2019/07/10/5d25a89be90db19297.png" alt="20190710165803.png"></p><p>用不同尺度的 pooling 来得到多样的信息，然后 upsample 到同样大小并 concat 起来，再分两个 branch，其中一路是 attention，最后 element-wise 乘到 feature map 上做 scaling。</p><p>multi channel selection 是说把这么多中间结果配上 weight，然后乘起来求个和。</p><p><img src="https://i.loli.net/2019/07/10/5d25aa1f814bd98800.png" alt="20190710170431.png"></p><p>在两阶段中 G 和 D 好像都是 share weight 的吧。作者表示这样可以 reduce the network capacity。</p><p>为了解决开头提出的 noisy semantic label 的问题，本文提出一种 uncertainty-guided pixel loss。</p><p><img src="https://i.loli.net/2019/07/10/5d25ace1a859026249.png" alt="20190710171617.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;用 semantic 信息来指到生成 cross view 的图片&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>Homomorphic Latent Space Interpolation for Unpaired Image-to-image Translation</title>
    <link href="https://ir1d.cf/2019/07/10/Homomorphic-Latent-Space-Interpolation-for-Unpaired-Image-to-imageTranslation/"/>
    <id>https://ir1d.cf/2019/07/10/Homomorphic-Latent-Space-Interpolation-for-Unpaired-Image-to-imageTranslation/</id>
    <published>2019-07-09T17:03:21.000Z</published>
    <updated>2019-07-10T08:48:04.169Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Latent Space Interpolation</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>在隐空间中找一条路径，来从一个 domain 的图片转移到另一个 domain。</p><h2 id="解决的思路"><a href="#解决的思路" class="headerlink" title="解决的思路"></a>解决的思路</h2><p>基于这样一个假设：深度神经网络可以把自然图片给 model 成 flag and smooth 的分布。</p><p>但是这样存在一个问题，这个方法直接映射出来的图片并不能区分不同的 attribute，中间 interpolate 出来的过渡并不平滑（比如下图的嘴直接闭上了..）所有的 attribute 沿着 interpolation 的路径一起变化的时候，用户就无法控制其中的某些特定 attribute 了</p><p><img src="https://i.loli.net/2019/07/10/5d24c95fd447488793.png" alt="20190710010534.png"></p><p>有没有办法找一条路对应到特定的 attribute 呢？之前有的工作是设定一些 attribute vector 来试图精细地控制。怎么生成呢？先生成一些关于这个 attribute 的正负样本，然后分别求两个聚类的均值，就得到了这样一个 vector。这样操作的局限性在于，忽略了很多 attribute 是 multi-modal 的，用一个 universal 的 smile 来 interpolate 最终只能生成一个 average 的 smile。</p><h2 id="核心知识点"><a href="#核心知识点" class="headerlink" title="核心知识点"></a>核心知识点</h2><p>文中定义一些 grouped feature，比如各种情绪（喜怒哀乐这种），然后目标是学习 Encoder（E），使得 $F_i = E(I_i), F_j = E(I_j), I(F_i, F_j)$ 是 interpolate 出来的结果要尽量真实。用一个 decoder 来把 latent feature 给 map 回 image space，这样设计来保证 feature 没有丢失原图的信息。</p><p>Decoder 和 Reconstruction 都是用 perceptual loss 训的。</p><p>本文的 encoder 在训练的时候是用 vgg 的 intermediate layer 当做 guide 来学的，具体来说是 minimize $E(I)$ 过一个 1x1 conv 之后和 VGG 的 <code>ReLU5_1</code> 层输出的 l2 loss。作者表示这一层的 semantic information 起到了额外的 guidance 作用，相当于是一项 regularization。</p><p>作者表示 $F<em>i + \alpha (F_j-F_i)$ 这么 interpolate 的话只定义了一种插值方式。文中作者对这个公式进行了扩展，变为 $I_v(F_i, F_j) = F_i + \sum</em>{k=1}^c v^k T^k(F_j-F_i)$。</p><p>作者通过同态来解决这个问题<img src="https://i.loli.net/2019/07/10/5d25a3f82a3f753698.png" alt="20190710163815.png"> 这里的 A 是把 latent feature 转成 attribute vector 的映射。</p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Latent Space Interpolation&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>Latent Filter Scaling for Multimodal Unsupervised Image-to-Image Translation</title>
    <link href="https://ir1d.cf/2019/07/08/Latent-Filter-Scaling-for-Multimodal-Unsupervised-Image-to-Image-Translation/"/>
    <id>https://ir1d.cf/2019/07/08/Latent-Filter-Scaling-for-Multimodal-Unsupervised-Image-to-Image-Translation/</id>
    <published>2019-07-08T01:15:06.000Z</published>
    <updated>2019-07-08T04:50:25.223Z</updated>
    
    <content type="html"><![CDATA[<ul><li>多个 target domain 的 image to image translation</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>Multimodeal unsupervised image-to-image translation —— translate an image from the source domain to many images in the target domain.</p><p>之前的方法更多的是 unconditional 地把 latent code 给 map 到 image。本文把 latent vector 用来修改 Convolution filter，进一步实现了 source domain content 和 target domain style 的 disentanglement。</p><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><p>有比较多的工作致力于保证 vector 到 image 的这样一个 mapping 的质量上。</p><p>InfoGAN 通过 disentanglement 来提升修改 latent code 的可解释性.</p><p>其他一些方法也试图让两个 latent code 进行 interpolation，要求生成的图片也是对应地 semantically interpolated。</p><p>也有一些方法考虑的是寻找 application-specific disentangled mapping，希望修改 latent code 的某一部分能修改到生成图片的某一部分。</p><p>CycleGAN 用了 cycle-consistency loss 来保证 image quality。</p><p>对于 conditional 的 image to image translation，之前的方法有的把 latent vector 和 input image 给 concat 起来，然后说这样往往会导致网络忽略 latent code。Conditional 任务最大的困难之处在于，既要保留原图片的结构，又要保证 latent vector 产生的 influence 和 variability。任务的核心是对于输入的 image 和 vector，通过改变 vector 可以改变输出图片的 appearance，从而使用不同的 vector 来生成不同 target domain 的图片。</p><p>PixelNN 中需要把 some form of output image 也喂给 GAN 来实现 multi-modality。这里面 some form 就比如是 low resolution 的 image<br>或者 normal map，然后这种额外的信息会控制最终的输出图片。MADGAN 和 Casacded Refinement Networks 都局限于只能对 a constant and discrete number 的 target domain 起作用。</p><p>latent code 也经常被看做是 output image 的 compressed form。这样训练之后常常可以发现网络把 input vector 中的某些部分对应到 output image 的一些 semantic 特征，比如说 MNIST 里 vector 的某一维度就可能对应到生成图片的笔迹的宽度或角度。之前的方法往往设计成不断把 input image 进行压缩，直至把它和 latent code concat 起来有用。最成功的一种实现是通过 disentanglement，限制 compression 的过程，把每个图片看作是 latent code 和 content code 两部分决定的。latent code 是 domain specific，而 content code 是在 source 和 target 之间 shared。（MUNIT）</p><h2 id="解决的思路"><a href="#解决的思路" class="headerlink" title="解决的思路"></a>解决的思路</h2><p>这篇文章从 Convolution filter 的角度出发，认为 disentanglement 其实是不必要的。</p><p>之前的工作一般把 latent code 看做是全图的 encoded data，把这个 code 和 input image 直接 concat 起来或者经过 encoding 之后再 concat 起来。</p><p>本文中作者认为可以把 latent code 看做是局部变化的 modulator，用来描述网络 convolution 操作的 modifier。之前的方法更多的是通过在 input image 后 concat 不同 channel 的信息，而本文中就好比是用不同的笔刷在图片上操作。</p><p>“latent code corresponds to local changes in the input image”</p><h2 id="核心知识点"><a href="#核心知识点" class="headerlink" title="核心知识点"></a>核心知识点</h2><p>具体操作就是：给出一个 k 维的 latent code，和一张输入图像，将 latent code 送入一个全连接网络来为每一个卷积层产生一个 scaler（这个 scaler 应该就是一个标量，来调节卷积核的尺度）。然后将图像送入卷积网，每一个卷积核都被对应的 scalar 所缩放。简单的说，就是让 k*1 维的标量 z，每一个维度都与 feature map 相乘。</p><p><img src="https://i.loli.net/2019/07/08/5d22af349974087156.png" alt="20190708104923.png"></p><p>这个 scalar 作用在 feature map 和作用在 filter 上是等价的，放在 feature map 上更好实现一些。</p><h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>MUNIT 是可以 disentangle input image 然后做 style transfer，而本文方法是在 target domain 的 disentanglement，每一种 noise code 对应一种 style。</p><h2 id="改进（？）"><a href="#改进（？）" class="headerlink" title="改进（？）"></a>改进（？）</h2><h2 id="other-comment"><a href="#other-comment" class="headerlink" title="other comment"></a>other comment</h2><p><a href="https://blog.csdn.net/qq_35422491/article/details/90677705" target="_blank" rel="noopener">https://blog.csdn.net/qq_35422491/article/details/90677705</a></p><p>添加一个可训练的全连接网络来将 latent code 映射成 scalar 来与网络的每一个 feature map 相乘。这个 scalar 是在 ReLU 和 normalization 的操作之前直接卷积层的输出相乘的</p><p>作者用一个 subsection 比较了一下 AdaIN。AdaIN 中是简单地用 input style “去计算” 这个 scale，而本文中是从 latent code 中学出来这个 scale。（但我觉得貌似 AdaIN 也可以看做是学出来的吧）。不过有一点区别的确，本文中的 scale 乘上 feature map 的操作是在 normalization 之前（等价于 filter scaling），而 AdaIN 应该是之后。</p><p><img src="https://i.loli.net/2019/07/08/5d22b0c94467e95237.png" alt="20190708105608.png"><img src="https://i.loli.net/2019/07/08/5d22b2d1a481e53108.png" alt="20190708110448.png"></p><p>StyleGAN 在这点上就很像了，作用在 AdaIN 上相当于是 scaling 了。</p><p>为什么我觉得有点像 stylegan 在 multimodel i2i 上的应用..</p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;多个 target domain 的 image to image translation&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>Towards Instance-level Image-to-Image Translation</title>
    <link href="https://ir1d.cf/2019/07/05/Towards-Instance-level-Image-to-Image-Translation/"/>
    <id>https://ir1d.cf/2019/07/05/Towards-Instance-level-Image-to-Image-Translation/</id>
    <published>2019-07-05T15:28:03.000Z</published>
    <updated>2019-07-05T15:28:30.482Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/07/05/5d1f6c921995c60099.png" alt="20190705232817.png"></p><p><img src="https://i.loli.net/2019/07/05/5d1f6c969891e72563.png" alt="20190705232821.png"><br>首先说下 MUNIT 等 Image to Image transmission 的不足之处（如图），需要 instance aware 的操作来保证图中的 Obejcts 也经过了stylization。</p><p>作者分析了一下 related works 的缺点：CycleGAN 假设在两种 mapping 作用下，latent space 是可分的。UNIT 中假定两个 domain 的图片可以通过某种方式 mapping 到一个共享的 latent space。MUNIT 和 DRIT 进一步假定这些 latent space 都可以 disentangle 成共享的 content space 和 domain-specific 的 attribute space。</p><p><img src="https://i.loli.net/2019/07/05/5d1f6c9d4cab154606.png" alt="20190705232828.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/05/5d1f6c921995c60099.png&quot; alt=&quot;20190705232817.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/05/
      
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>Learning Pyramid-Context Encoder Network for High-Quality Image Inpainting</title>
    <link href="https://ir1d.cf/2019/07/05/Learning-Pyramid-Context-Encoder-Network-for-High-Quality-Image-Inpainting/"/>
    <id>https://ir1d.cf/2019/07/05/Learning-Pyramid-Context-Encoder-Network-for-High-Quality-Image-Inpainting/</id>
    <published>2019-07-05T15:25:06.000Z</published>
    <updated>2019-07-05T15:26:33.069Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/07/05/5d1f6bfda431333221.png" alt="20190705232548.png"></p><p>这篇 inpainting 的工作比较有意思，它没有 follow partial convolution 这种思路，而是使用的原版的 convolution。这个 PeN-Net是基于 UNet设计的，先是一个  pyramid-context encoder，再是一个 multi-scale decoder 。 Decoder中间加了一些 Attention Module，它里面使用了 dilated conv 的分组卷积，扩大了感受野同时不会增大很多运算开销。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/05/5d1f6bfda431333221.png&quot; alt=&quot;20190705232548.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;这篇 inpainting 的工作比较有意思，它没有 follow partia
      
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="inpainting" scheme="https://ir1d.cf/tags/inpainting/"/>
    
  </entry>
  
  <entry>
    <title>Attention-guided Network for Ghost-free High Dynamic Range Imaging</title>
    <link href="https://ir1d.cf/2019/07/05/Attention-guided-Network-for-Ghost-free-High-Dynamic-Range-Imaging/"/>
    <id>https://ir1d.cf/2019/07/05/Attention-guided-Network-for-Ghost-free-High-Dynamic-Range-Imaging/</id>
    <published>2019-07-05T15:24:35.000Z</published>
    <updated>2019-07-05T15:24:54.910Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2019/07/05/5d1f6bc007b8788474.png" alt="20190705232446.png"></p><p>AHDRNet 是用来解决 Ghost-Free 地 HDR。</p><p>DRDBs是  dilated residual dense blocks。</p><p>先用一个 attention module 来处理 misalignment 和 saturation，然后再用 DRDB 来进行 Merging Network</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/07/05/5d1f6bc007b8788474.png&quot; alt=&quot;20190705232446.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;AHDRNet 是用来解决 Ghost-Free 地 HDR。&lt;/p&gt;
&lt;p&gt;D
      
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="HDR" scheme="https://ir1d.cf/tags/HDR/"/>
    
  </entry>
  
  <entry>
    <title>Foreground-aware Image Inpainting</title>
    <link href="https://ir1d.cf/2019/07/05/Foreground-aware-Image-Inpainting/"/>
    <id>https://ir1d.cf/2019/07/05/Foreground-aware-Image-Inpainting/</id>
    <published>2019-07-05T15:23:38.000Z</published>
    <updated>2019-07-05T15:26:38.438Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Inpainting guided by edges.</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>这篇文章是专注于前景物品的 inpainting 上。作者考虑到对背景的 inpainting 不是那么 challenging，以为背景一般都挺常见的，而前景物品是我们关注的重点，更希望能较好地处理它。具体做法是先找到前景物品，然后求它的 contour（edge），再对这个 contour 进行修补，最后用我们补好的 contour 来还原回整图。网络结构设计也是一个 coarse-to-fine 的思路。</p><p><img src="https://i.loli.net/2019/07/05/5d1f6b9c48a5b82913.png" alt="20190705232410.png"></p><p><img src="https://i.loli.net/2019/07/05/5d1f6ba09b9a768963.png" alt="20190705232415.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Inpainting guided by edges.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="inpainting" scheme="https://ir1d.cf/tags/inpainting/"/>
    
  </entry>
  
  <entry>
    <title>Free-Form Image Inpainting with Gated Convolution</title>
    <link href="https://ir1d.cf/2019/07/05/Free-Form-Image-Inpainting-with-Gated-Convolution/"/>
    <id>https://ir1d.cf/2019/07/05/Free-Form-Image-Inpainting-with-Gated-Convolution/</id>
    <published>2019-07-05T15:22:10.000Z</published>
    <updated>2019-07-05T15:22:54.629Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Gated Conv</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>这篇文章承接之前 Partial Convolution 的思路，说把所有 pixel 一视同仁的 convolution 会生成一些扭曲的效果图，基于同样的思路，我们在 convolution 的时候加一个 mask 上去来 guide 它学习没有洞的部分的信息。</p><h2 id="解决的思路"><a href="#解决的思路" class="headerlink" title="解决的思路"></a>解决的思路</h2><p>与 partial convolution 不同的是，partial convolution 中的 guiding mask 是通过 pooling 等操作得到的，而 gated convolution 让一个 convolution 支路来学这个 mask。通过这种方式来起到类似于 spatial attention 的效果。<br>实现上 Gated Convolution 就是用一个支路过 convolution，activation，batchnorm，然后再 sigmoid，并乘回另一支路经过一个 convolution 后的结果。</p><p><img src="https://i.loli.net/2019/07/05/5d1f6b49625e777807.png" alt="20190705232248.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Gated Conv&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="inpainting" scheme="https://ir1d.cf/tags/inpainting/"/>
    
  </entry>
  
  <entry>
    <title>Learning Raw Image Denoising with Bayer Pattern Unification and Bayer Preserving Augmentation</title>
    <link href="https://ir1d.cf/2019/07/05/Learning-Raw-Image-Denoising-with-Bayer-Pattern-Unification-and-Bayer-Preserving-Augmentation/"/>
    <id>https://ir1d.cf/2019/07/05/Learning-Raw-Image-Denoising-with-Bayer-Pattern-Unification-and-Bayer-Preserving-Augmentation/</id>
    <published>2019-07-05T15:05:48.000Z</published>
    <updated>2019-07-05T15:14:43.926Z</updated>
    
    <content type="html"><![CDATA[<ul><li>NTIRE Real Denoising 的冠军 team 的 report</li></ul><a id="more"></a><h2 id="主要解决什么问题"><a href="#主要解决什么问题" class="headerlink" title="主要解决什么问题"></a>主要解决什么问题</h2><p>对 Raw 图片做 Unify、 Data Augmentation。</p><p>不然一种 model 只能处理数据集里的某一种 Bayer Pattern，只利用到一个 subset。</p><h2 id="核心知识点"><a href="#核心知识点" class="headerlink" title="核心知识点"></a>核心知识点</h2><p>BayerUnify 是说通过 Crop 来把不同的 Bayer Pattern 给归一化。由于 challenge 在用 SIDD 数据集，它是由很多种相机拍出来的，有 3 种不同的 Bayer Pattern。如果针对某一种 Bayer Pattern 处理的话不能充分利用训练集，测试的时候也需要训练三种 model 交上去。<br><img src="https://i.loli.net/2019/07/05/5d1f691265f7c40221.png" alt="20190705231321.png"></p><p>Report 里是选用 BGGR 的形式（按照左上、右上、左下、右下的顺序）当做基准，把其他的几种通过 padding + crop 来变成 BGGR。测试的时候是先做 padding，然后 denoise，最后再把 padding 和多余的部分给 crop 掉就好了。</p><p><img src="https://i.loli.net/2019/07/05/5d1f691d1d32f71957.png" alt="20190705231332.png"></p><p>BayerAug 解决的是 RAW 图片做 Data Augmentation 的问题。陈启峰在 Seeing In The Dark 里面是把 Bayer Pattern 给展开成一个 4 channel 的 feature map，大家之后也大多是这么用的。在这个 4 channel 的 map 上直接 flip 的话没办法对应回一个有实际意义的 Bayer Pattern。（比如第四行的图片就有明显的失真）</p><p><img src="https://i.loli.net/2019/07/05/5d1f69253901167968.png" alt="20190705231340.png"></p><p>为了解决这个问题，BayerAug 是这么操作的：把 Flip 和 Crop 结合起来，在 Flip 之后适当地 Crop 来保证它 Bayer Pattern 有意义，且不改变——还是 BGGR（我们选的那个基准）</p><p><img src="https://i.loli.net/2019/07/05/5d1f692f6382010594.png" alt="20190705231350.png"></p><h2 id="other-comment"><a href="#other-comment" class="headerlink" title="other comment"></a>other comment</h2><p>整个 challenge 大家基本上在用 UNet，他们选择的方案也是用 MaxPool+Deconv 搭建的 UNet。读完之后我觉得他们排名比较好还是主要靠的 BayerUnify 和 BayerAug 来进行类似 Data Augmentation 的操作。</p><p><img src="https://i.loli.net/2019/07/05/5d1f6906e128733481.png" alt="20190705231308.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;NTIRE Real Denoising 的冠军 team 的 report&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="Raw" scheme="https://ir1d.cf/tags/Raw/"/>
    
      <category term="Denoise" scheme="https://ir1d.cf/tags/Denoise/"/>
    
  </entry>
  
  <entry>
    <title>Digital Image Modalities and Processing</title>
    <link href="https://ir1d.cf/2019/06/24/Digital-Image-Modalities-and-Processing/"/>
    <id>https://ir1d.cf/2019/06/24/Digital-Image-Modalities-and-Processing/</id>
    <published>2019-06-24T13:28:58.000Z</published>
    <updated>2019-07-05T15:05:06.504Z</updated>
    
    <content type="html"><![CDATA[<p>-</p><a id="more"></a><h2 id="Low-level"><a href="#Low-level" class="headerlink" title="Low level"></a>Low level</h2><p>preprocessing to remove noise, shadow or enhance an image.</p><p>image -&gt; image</p><h2 id="mid-level"><a href="#mid-level" class="headerlink" title="mid level"></a>mid level</h2><p>segmenting an image into regions / objects;<br>describing an image concisely</p><p>image -&gt; attributes (edges, lines, regions)</p><h2 id="high-level"><a href="#high-level" class="headerlink" title="high level"></a>high level</h2><p>make sense of an image; image understanding</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;-&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="DIP" scheme="https://ir1d.cf/tags/DIP/"/>
    
  </entry>
  
  <entry>
    <title>算分期末复习</title>
    <link href="https://ir1d.cf/2019/06/21/%E7%AE%97%E5%88%86%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ir1d.cf/2019/06/21/算分期末复习/</id>
    <published>2019-06-21T15:50:36.000Z</published>
    <updated>2019-06-21T15:53:57.567Z</updated>
    
    <content type="html"><![CDATA[<ul><li><p>复习得很用心吧。。但是考得挺难的。。感觉有点白给了。。</p></li><li><p>最后一题题面没说整数，顺手写了个梯度下降，好不容易老师溜达过来问了一嘴发现是整数。。。</p></li></ul><a id="more"></a><p>课本例题<br>课本习题 还差 7,9,11<br>ppt 例题<br>21 个 npc <a href="http://wmdcstdio.com/2018/06/23/karp-npc-21/" target="_blank" rel="noopener">http://wmdcstdio.com/2018/06/23/karp-npc-21/</a><br>24 网络流 <a href="https://blog.csdn.net/herano/article/details/70180828" target="_blank" rel="noopener">https://blog.csdn.net/herano/article/details/70180828</a><br><a href="https://www.zjyelizaveta.com/2017/09/21/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E7%BD%91%E7%BB%9C%E6%B5%8124%E9%A2%98-Part-1/" target="_blank" rel="noopener">https://www.zjyelizaveta.com/2017/09/21/%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E7%BD%91%E7%BB%9C%E6%B5%8124%E9%A2%98-Part-1/</a><br>算导 平摊分析 网络流</p><p>可行流：加一个新源点 限制流量<br>上下界网络流</p><p>最小割输出方案 <a href="https://blog.csdn.net/semiwaker/article/details/62883701" target="_blank" rel="noopener">https://blog.csdn.net/semiwaker/article/details/62883701</a><br>残量网络里和 S 连通的点是 S 点集里的点</p><p>回溯法 各种树 多米诺性质<br><img src="https://user-images.githubusercontent.com/10709657/59009078-dd24f180-885e-11e9-991a-3a25ab0eddd6.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59009081-e2823c00-885e-11e9-9d8b-f612f9e65184.png" alt="image">最后的结果是 z0?</p><p><img src="https://user-images.githubusercontent.com/10709657/59011172-51af5e80-8866-11e9-9cf2-8f056d293a98.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59054095-89012800-88c5-11e9-9944-3338b0a90108.png" alt="image"><br>逆序数列：在 i 右边，并且小于 i 的元素个数记作 B_i<br>heapify 是从 i 向叶子调整（把儿子中较大的换到父结点），复杂度依赖于结点的高度<br><img src="https://user-images.githubusercontent.com/10709657/59076291-e918be00-8907-11e9-8228-d7203c2216da.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59076728-19f9f280-890a-11e9-8f08-ef75f27a693c.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59076936-15820980-890b-11e9-8338-b3385eaba55d.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59077335-c50bab80-890c-11e9-82b8-6fe9d3b6d3ec.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59077878-07ce8300-890f-11e9-8334-7c255b264747.png" alt="image"><br>P 规约到 Q，说明 Q 至少和 P 一样难，复杂度不会低于 P</p><p><img src="https://user-images.githubusercontent.com/10709657/58977562-97cfd800-87fc-11e9-9caa-c30ddebb1acb.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/58977593-a3bb9a00-87fc-11e9-9ef5-26678699d376.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/58977778-f39a6100-87fc-11e9-9ca1-c9ee015a2079.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59001595-be643200-8841-11e9-91cb-e819d45a01e3.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59002250-595e0b80-8844-11e9-9600-1f509cc62b9c.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59002256-5e22bf80-8844-11e9-9658-9e695c4fb52c.png" alt="image"><br>递归树<br>dp: 一个最优决策序列的任何子序列本身一定是相对于<br>子序列的初始和结束状态的最优的决策序列<br>贪心：<br><img src="https://user-images.githubusercontent.com/10709657/59003644-67625b00-8849-11e9-9f12-c49bf8d98b14.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59003769-d9d33b00-8849-11e9-8005-1f75c4ceaaa8.png" alt="image"><br>套路<br><img src="https://user-images.githubusercontent.com/10709657/59003777-e2c40c80-8849-11e9-97d4-ff9a001964e7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59003789-e9528400-8849-11e9-9fd6-61c24ea4d771.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59003794-f1aabf00-8849-11e9-87da-dbe8b55ede77.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59003814-05eebc00-884a-11e9-8e37-a0ad2255aba1.png" alt="image"></p><p>贪心证 prim,kruskal,dijkstra</p><p>3SAT 是说 3 元合取范式，MAX-SAT 是说一堆合取范式里能不能满足 k 个</p><p>构件设计法</p><p><img src="https://user-images.githubusercontent.com/10709657/59104342-eea3f180-8963-11e9-8dda-e8d05c95251d.png" alt="image"></p><p>近似算法的证明。。<br><img src="https://user-images.githubusercontent.com/10709657/59114336-8d871880-8979-11e9-8247-dc7e881856b7.png" alt="image"></p><p>NPC 证明</p><p>Karp 的 21 道 NPC 证明（去年小班课必读论文）</p><p><a href="https://people.eecs.berkeley.edu/~luca/cs172/karp.pdf" target="_blank" rel="noopener">https://people.eecs.berkeley.edu/~luca/cs172/karp.pdf</a></p><p>中文简易版</p><p><a href="http://wmdcstdio.com/2018/06/23/karp-npc-21/" target="_blank" rel="noopener">http://wmdcstdio.com/2018/06/23/karp-npc-21/</a></p><p>14 个 NPC 证明</p><p><a href="http://www.docin.com/p-789421911.html" target="_blank" rel="noopener">http://www.docin.com/p-789421911.html</a></p><p>CSDN 比较好的博客</p><p><a href="https://blog.csdn.net/golden1314521/article/details/51470999" target="_blank" rel="noopener">https://blog.csdn.net/golden1314521/article/details/51470999</a></p><p>百度文库 NPC 问题整理</p><p><a href="https://wenku.baidu.com/view/65e548191a37f111f0855b2c?pcf=2" target="_blank" rel="noopener">https://wenku.baidu.com/view/65e548191a37f111f0855b2c?pcf=2</a></p><p>网络流 24 题</p><p>一篇比较全的博客</p><p><a href="https://www.cnblogs.com/zsnuo/p/8909613.html" target="_blank" rel="noopener">https://www.cnblogs.com/zsnuo/p/8909613.html</a></p><h2 id="09"><a href="#09" class="headerlink" title="09"></a>09</h2><p><img src="https://user-images.githubusercontent.com/10709657/59114553-f9698100-8979-11e9-8acc-2e971cad9855.png" alt="image"><br>平摊分析的三种方法<br>– 聚集分析<br>– 记账法<br>– 势能法<br><img src="https://user-images.githubusercontent.com/10709657/59114611-1900a980-897a-11e9-82e2-ccf8719c594b.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59116219-aabde600-897d-11e9-9f20-f5a9e67841a1.png" alt="image"></p><p>我觉得有问题的：平摊分析、网络流、近似、随机<br>贪心证明：线段覆盖</p><p><img src="https://user-images.githubusercontent.com/10709657/59117443-46e8ec80-8980-11e9-9d3c-e146304c14e7.png" alt="image"><br>dinic n^3 ff mC ek nm^2</p><h2 id="网络流-24"><a href="#网络流-24" class="headerlink" title="网络流 24"></a>网络流 24</h2><p>最大权闭合子图的权值等于所有正权点之和减去最小割 <a href="https://blog.csdn.net/yo_bc/article/details/75322370" target="_blank" rel="noopener">https://blog.csdn.net/yo_bc/article/details/75322370</a> S 连正权，T 连负权，原图的边容量 inf<br>最小路径覆盖：方案即为 S 出发的所有满流边，每条满流边上的点<br>二分图最小点权覆盖、最大点权独立集 转化为最大匹配<br>|最大独立集| = |V|-|最大匹配数|<br>路径互不相交 -&gt; 不能重点，不能重边 -&gt; 说明了每个点只能经过一次<br>仅在数字结点处相交 -&gt; 可以重点，不能重边 -&gt; 不用拆点，只限制边权即可<br>最大权不相交路径问题转化为最大费用最大流模型<br>21、最长 k 可重区间集问题 要想一会。。把重复 k 次转换成选 k 条路径，每条路径内部区间互不相交</p><ol><li>平面上线段：为了避免线段与 x 轴垂直的情况，需要将所有的端点坐标 ×2 ，然后左端点 −1</li></ol><h2 id="18"><a href="#18" class="headerlink" title="18"></a>18</h2><p>恰好覆盖：写出算法及复杂度<br>NPC 证明：证明强独⽴集是 NPC 的<br>近似算法：证明最⼩顶点覆盖的 MVC 算法的正确性即近似⽐</p><p>有向环覆盖对应拆点后二分图的完备匹配 <a href="https://blog.csdn.net/u013480600/article/details/39159407" target="_blank" rel="noopener">https://blog.csdn.net/u013480600/article/details/39159407</a><br>我们找到这 n 条边，起点互不相同、终点互不相同，可以认为是构成若干个环</p><h2 id="近似"><a href="#近似" class="headerlink" title="近似"></a>近似</h2><p>近似算法：写出求极大匹配的贪心算法，求该算法和最大匹配算法的近似比，找出紧实例<br>证明最⼩顶点覆盖的 MVC 算法的正确性即近似⽐</p><h2 id="随机"><a href="#随机" class="headerlink" title="随机"></a>随机</h2><p>伪码，输出一个不是最大的随机数</p><h2 id="npc"><a href="#npc" class="headerlink" title="npc"></a>npc</h2><p>恰好覆盖：写出算法及复杂度</p><p>找数组中出现次数超过一半的元素 O（n）</p><p>课后题<br>Select 算法 3 个一组，nlogn<br>5 个 n</p><h2 id="12"><a href="#12" class="headerlink" title="12"></a>12</h2><p><img src="https://user-images.githubusercontent.com/10709657/59149679-41a4a400-8a4b-11e9-8028-e155a2bea89d.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59150705-5ccae000-8a5a-11e9-83bb-d66d8e19ee91.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59155750-fcbc5400-8ac2-11e9-8202-4323659837dd.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59155754-0776e900-8ac3-11e9-94b9-6df0176d7e67.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59155756-0fcf2400-8ac3-11e9-92f3-a10f9b901815.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59155758-13fb4180-8ac3-11e9-9012-5691f29da5f3.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59155761-1bbae600-8ac3-11e9-8122-9ac77dd8730e.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59156271-bec32e00-8aca-11e9-8954-cb0908961592.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59159940-33b25a00-8b03-11e9-9d43-da5597a30c23.png" alt="image"></p><p><a href="https://cs.stackexchange.com/questions/1240/how-do-i-construct-reductions-between-problems-to-prove-a-problem-is-np-complete" target="_blank" rel="noopener">https://cs.stackexchange.com/questions/1240/how-do-i-construct-reductions-between-problems-to-prove-a-problem-is-np-complete</a></p><p>First, unless you’re just doing homework, you have to decide which NP-hard problem to reduce to your problem. This is largely a question of “smell”. If the number 3 appears anywhere in the problem statement, try reducing from 𝟥𝖲𝖠𝖳 or 𝟥𝖢𝗈𝗅𝗈𝗋 or 𝟥𝖯𝖺𝗋𝗍𝗂𝗍𝗂𝗈𝗇. (Yes, I’m serious.) If your problem involves finding an optimal subsequence or permutation or path, try reducing from 𝖧𝖺𝗆𝗂𝗅𝗍𝗈𝗇𝗂𝖺𝗇𝖢𝗒𝖼𝗅𝖾 or 𝖧𝖺𝗆𝗂𝗅𝗍𝗈𝗇𝗂𝖺𝗇𝖯𝖺𝗍𝗁. If your problem asks for the smallest subset with a certain property, try 𝖢𝗅𝗂𝗊𝗎𝖾; if it asks for the largest subset with a certain property, try 𝖨𝗇𝖽𝖾𝗉𝖾𝗇𝖽𝖾𝗇𝗍𝖲𝖾𝗍. If your problem involves doing something in the plane, try 𝖯𝗅𝖺𝗇𝖺𝗋𝖢𝗂𝗋𝖼𝗎𝗂𝗍𝖲𝖠𝖳 or 𝖯𝗅𝖺𝗇𝖺𝗋𝖳𝖲𝖯. And so on. If your problem doesn’t “smell” like anything, 𝟥𝖲𝖠𝖳 or 𝖢𝗂𝗋𝖼𝗎𝗂𝗍𝖲𝖠𝖳 is probably your best bet.<br><img src="https://user-images.githubusercontent.com/10709657/59161956-c4952f80-8b1b-11e9-9af1-c9b99704a5b0.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;复习得很用心吧。。但是考得挺难的。。感觉有点白给了。。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;最后一题题面没说整数，顺手写了个梯度下降，好不容易老师溜达过来问了一嘴发现是整数。。。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="算分" scheme="https://ir1d.cf/tags/%E7%AE%97%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>概统期末复习</title>
    <link href="https://ir1d.cf/2019/06/21/%E6%A6%82%E7%BB%9F%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ir1d.cf/2019/06/21/概统期末复习/</id>
    <published>2019-06-21T15:47:16.000Z</published>
    <updated>2019-06-21T15:50:25.777Z</updated>
    
    <content type="html"><![CDATA[<ul><li>概统复习得很用心了，成绩也还算可以吧。。虽然和别人比菜了好多，但是是我目前为止分数最高的数学课了</li></ul><a id="more"></a><p><img src="https://user-images.githubusercontent.com/10709657/59337773-cf2a1180-8d33-11e9-9e5f-4bc6770ef5f4.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59337811-da7d3d00-8d33-11e9-87f1-7b67260cf66b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59337885-f7197500-8d33-11e9-8063-d415892f32bb.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59337906-fed91980-8d33-11e9-9503-52b4592095e2.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59338069-495a9600-8d34-11e9-810d-36d7a784faad.png" alt="image"></p><p>正态总体之样本均值与样本方差的一些结论<br>Lecture 7</p><p>同济三版：P169 7.22 最小/大 统计量 f_n = 1 - [1 - f] ^ n</p><p>拉格朗日乘数<br><img src="https://user-images.githubusercontent.com/10709657/59398051-55406980-8dc1-11e9-9b89-3b3d233406f9.png" alt="image"></p><p>P186 习题 8<br><img src="https://user-images.githubusercontent.com/10709657/59400228-51184a00-8dc9-11e9-8d06-e537a01670af.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400272-7b6a0780-8dc9-11e9-84fd-1802932cb628.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400280-80c75200-8dc9-11e9-9303-1d364753894b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400554-59bd5000-8dca-11e9-8117-b73e3b44fa51.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400798-3b0b8900-8dcb-11e9-9f14-1253c739c9ab.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400819-4b236880-8dcb-11e9-9f33-fbf4327eea77.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59400836-5aa2b180-8dcb-11e9-81db-c6ea334fcc99.png" alt="image"><br>矩估计法得到的估计量一般为一致估计量<br>在一定条件下, 极大似然估计也具有一致性</p><p><img src="https://user-images.githubusercontent.com/10709657/59405282-88442680-8ddc-11e9-9862-6387b8a458a7.png" alt="image"><br>对于单侧检验, 通常把希望的结果(或预计的结果)的反面取作 H</p><p>记第一类错误的概率为 (恰好为显著性 水平 alpha<br><img src="https://user-images.githubusercontent.com/10709657/59406387-8c724300-8de0-11e9-9027-c45851f8eb0d.png" alt="image"><br>在控制犯第一类错误的概率 alpha 的原则下， 通常将有把握的、有经验的结论作为原假 尽可能使后果严重的错误成为第一类错误<br>无偏检验 要求一个检验犯第一类错误的概率总不超过不犯第二类错误的概率<br><img src="https://user-images.githubusercontent.com/10709657/59407060-b0cf1f00-8de2-11e9-8ddb-934d39a23190.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59407066-b593d300-8de2-11e9-96a5-0930bc1153c5.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59407232-33f07500-8de3-11e9-9b4b-be7429627ddc.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59407240-38b52900-8de3-11e9-9edd-aebc1f420243.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59407245-3ce14680-8de3-11e9-8f6f-04bb1fd789d2.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408032-9a769280-8de5-11e9-8cd1-c56a00872471.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408044-9f3b4680-8de5-11e9-9f5e-a9172ee24718.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408053-a3fffa80-8de5-11e9-8ba0-5470becf78ae.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59408508-c21a2a80-8de6-11e9-9f5a-3b6d2560554a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408511-c5151b00-8de6-11e9-99c9-bd1cbd86d6af.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408516-c9d9cf00-8de6-11e9-887f-e6169ff67d09.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59408536-d2320a00-8de6-11e9-8592-b740c8496c0c.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59409294-854f3300-8de8-11e9-8534-b6d625d2a979.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59409381-b4fe3b00-8de8-11e9-9ce4-46abbf159c85.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59409462-dc550800-8de8-11e9-9d97-97cc3a1007d1.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59409581-16260e80-8de9-11e9-9ef5-7312a722a57f.png" alt="image"><br>vi : 频数 npi : 理论频数<br><img src="https://user-images.githubusercontent.com/10709657/59409773-9cdaeb80-8de9-11e9-9b5e-e655fe32e82b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59409784-a49a9000-8de9-11e9-9d66-af2beea1c47b.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59426905-f3f1b800-8e0b-11e9-9b30-1bf676078336.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59426908-f6541200-8e0b-11e9-871d-044decb804be.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59426914-f9e79900-8e0b-11e9-8d64-cb050997843f.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59427343-01f40880-8e0d-11e9-8f56-1e6c1797dd9d.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59427559-8181d780-8e0d-11e9-879c-37d81cfa43a0.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59438333-e47f6880-8e25-11e9-9890-25d9b46684a4.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59438339-e9dcb300-8e25-11e9-9c92-59c193e6eb76.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59442722-5ad39900-8e2d-11e9-84b7-2a74ba8a1940.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59442735-5e672000-8e2d-11e9-8304-d175daafd8a0.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59443697-02050000-8e2f-11e9-9d4d-6f4df44f7194.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59443716-09c4a480-8e2f-11e9-82d4-e8828a1cd746.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59443798-29f46380-8e2f-11e9-9255-0e986092bb12.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59444693-e3076d80-8e30-11e9-8756-8d61b3a73666.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59446419-0e3f8c00-8e34-11e9-8925-0fe94b3765e1.png" alt="image"><br>显著水平越小，接受域的范围越大</p><p><img src="https://user-images.githubusercontent.com/10709657/59563647-349d3b80-906f-11e9-99d9-002602966570.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59563699-f9e7d300-906f-11e9-8d52-3dbce736a0de.png" alt="image"></p><p>9.1 P32 两类错误的关系</p><p><img src="https://user-images.githubusercontent.com/10709657/59564475-ee010e80-9079-11e9-8dcb-cdb4c5f3e428.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59564483-0113de80-907a-11e9-96ba-ae63890ff0eb.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59564493-256fbb00-907a-11e9-9822-b38d0d629aa7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59564496-315b7d00-907a-11e9-932e-4faa8ad4b021.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59564535-97e09b00-907a-11e9-859a-e71825fe154f.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;概统复习得很用心了，成绩也还算可以吧。。虽然和别人比菜了好多，但是是我目前为止分数最高的数学课了&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="概统" scheme="https://ir1d.cf/tags/%E6%A6%82%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>代组期末复习</title>
    <link href="https://ir1d.cf/2019/06/21/%E4%BB%A3%E7%BB%84%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ir1d.cf/2019/06/21/代组期末复习/</id>
    <published>2019-06-21T15:46:09.000Z</published>
    <updated>2019-06-21T15:47:28.363Z</updated>
    
    <content type="html"><![CDATA[<ul><li>代组我没了。。填空题期望得分太低。。证明题也白给了。。ggggg</li></ul><a id="more"></a><p>第 20 章<br><img src="https://user-images.githubusercontent.com/10709657/59200905-d8986a00-8bcb-11e9-8970-ca4c2fcdcbef.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59203892-17c9b980-8bd2-11e9-9fd6-71e4853899e6.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59204417-29f82780-8bd3-11e9-8e81-ea3f0472bd7e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59204866-24e7a800-8bd4-11e9-989f-137e0396289e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59204949-59f3fa80-8bd4-11e9-81f9-5ca088235eb7.png" alt="image"><br>任何一个足够大的结构中必定包含一个给定大小的规则子结构<br>R(a, 2)=R(2, a)=a R(a, b)=R(b, a)<br><img src="https://user-images.githubusercontent.com/10709657/59205415-73497680-8bd5-11e9-9579-af1acd900282.png" alt="image"></p><p>21 章<br><img src="https://user-images.githubusercontent.com/10709657/59210271-cd4f3980-8bdf-11e9-9557-59f68ada3a47.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59210388-11423e80-8be0-11e9-8edd-55b0d465515a.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59210816-089e3800-8be1-11e9-93f7-d15711b00d65.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211000-66328480-8be1-11e9-9e33-9844b046c181.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211265-0be5f380-8be2-11e9-9e30-9b717a8706eb.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211303-1ef8c380-8be2-11e9-8fe1-268038a9eba0.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211320-2ae48580-8be2-11e9-86f4-ea75cf4cc249.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211373-42bc0980-8be2-11e9-8b8b-a7655184fc0d.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59211572-bc53f780-8be2-11e9-8498-553fe3abe94c.png" alt="image"></p><p>22 章<br><img src="https://user-images.githubusercontent.com/10709657/59240749-ac1a3780-8c37-11e9-87ab-9b07c1322796.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59241558-bbe74b00-8c3a-11e9-8a9f-cb53db1b7e18.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59251563-aaaf3600-8c5c-11e9-8374-f0cbf132a589.png" alt="image"></p><p>特解的求法：f(n)为 n 的 t 次多项式，一般 H*(n)也为 n 的 t 次多项式<br><img src="https://user-images.githubusercontent.com/10709657/59251138-a9313e00-8c5b-11e9-8e1f-f32a09993991.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59251636-db8f6b00-8c5c-11e9-951c-5ff62f74a90c.png" alt="image"><br>错排<br><img src="https://user-images.githubusercontent.com/10709657/59252484-bac81500-8c5e-11e9-82ee-392d24a0d273.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59255982-8d329a00-8c65-11e9-842f-1d38c98eac83.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59256308-44c7ac00-8c66-11e9-96f1-3ddcdca84418.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59257060-cd931780-8c67-11e9-9ed3-940137cbf9a7.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59257038-c409af80-8c67-11e9-8e5e-16c6f5bfd735.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59257769-2e6f1f80-8c69-11e9-8eb9-a583c16134a3.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59261589-57df7980-8c70-11e9-9735-cc3e4782e47a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59263029-ea811800-8c72-11e9-8eed-e3f6493a6a2c.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59263147-16040280-8c73-11e9-8e9d-831d472afc78.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59264350-8875e200-8c75-11e9-823e-5e71607b657d.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59264442-b1967280-8c75-11e9-9005-50dc534b2479.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59264910-bdceff80-8c76-11e9-9333-ec1e7790278c.png" alt="image"></p><p>22 章<br><img src="https://user-images.githubusercontent.com/10709657/59270918-405ebb80-8c85-11e9-917f-a5b14b769ec0.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59271048-9a5f8100-8c85-11e9-9513-b896defd6175.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59271179-dbf02c00-8c85-11e9-8e23-d9d5b2608444.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59271200-e7dbee00-8c85-11e9-973e-f13620c8c6c5.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59271214-eca0a200-8c85-11e9-91eb-882dedce4d43.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272188-0d69f700-8c88-11e9-8cf1-566ca57f60b2.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272201-13f86e80-8c88-11e9-9f25-cbb4675d986e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272272-4013ef80-8c88-11e9-8e6f-762fae284b6e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272304-50c46580-8c88-11e9-998e-8ea0c18fb6d2.png" alt="image"><br>n 元对称群 Sn， 在表示式中具有 r 个不交轮换的置换个数是 第一类 Stirling 数</p><p>n 个不同的球恰好放到 r 个相同的盒子里的方法数称为第二类 Stirling 数，<br><img src="https://user-images.githubusercontent.com/10709657/59272416-92eda700-8c88-11e9-9340-366efea8fdd7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272430-9719c480-8c88-11e9-862b-41422d102a78.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272647-0a233b00-8c89-11e9-95f1-4cb604c33071.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272735-43f44180-8c89-11e9-8980-11d0f0565bce.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272843-74d47680-8c89-11e9-939e-bbf1bdf1a0b0.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272964-bd8c2f80-8c89-11e9-9ef6-d5bf3a189aff.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59272996-d1379600-8c89-11e9-8998-1861fbd98c92.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59273033-e1e80c00-8c89-11e9-8007-e2dbc13dc198.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59317098-17294400-8cf4-11e9-9e13-72ce6b522af9.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59319057-ed741b00-8cfb-11e9-8010-e57773393f37.png" alt="image"><br>Burnside：对于一个置换 f,若一个染色方案 s 经过置换后不变，称 s 为 f 的不动点。将 f 的不动点数目记为 C(f)，则可以证明等价类数目为所有 C(f)的平均值。<br><img src="https://user-images.githubusercontent.com/10709657/59319118-1694ab80-8cfc-11e9-82b9-e0a2d013788d.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59319146-2e6c2f80-8cfc-11e9-91e8-149376357731.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59319908-f74b4d80-8cfe-11e9-8f6e-b2f66e188ec3.png" alt="image"></p><p>画 哈斯图<br>P344 组合恒等式</p><p>1/(1-x)^2 nx^(n-1)</p><p><img src="https://user-images.githubusercontent.com/10709657/59614597-aa7ad300-9153-11e9-98db-a54d4dee40dd.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59617878-b49fd000-9159-11e9-907a-9e175eab8137.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59617881-b6699380-9159-11e9-96d0-f294d22e4a95.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;代组我没了。。填空题期望得分太低。。证明题也白给了。。ggggg&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="代组" scheme="https://ir1d.cf/tags/%E4%BB%A3%E7%BB%84/"/>
    
  </entry>
  
  <entry>
    <title>数论期末复习</title>
    <link href="https://ir1d.cf/2019/06/21/%E6%95%B0%E8%AE%BA%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ir1d.cf/2019/06/21/数论期末复习/</id>
    <published>2019-06-21T15:44:23.000Z</published>
    <updated>2019-06-21T15:45:54.474Z</updated>
    
    <content type="html"><![CDATA[<ul><li>初等数论及其应用。。其实有点文科课了。。基本上在背公式。。证明题我是真的没证出来。。tktkddd 轻松秒了</li></ul><a id="more"></a><p><img src="https://user-images.githubusercontent.com/10709657/59699523-483dd300-9224-11e9-8f60-5d1ab1ea10a9.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59702932-71ae2d00-922b-11e9-95b6-7b5482379668.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59734165-e95b7680-9282-11e9-8f69-eebc9043b91a.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59739100-1402fa80-9296-11e9-863e-61fdfbd4bc2a.png" alt="image"><br>如果(𝑎, 𝑏) = 1, 那么(𝑎, 𝑏𝑐) = (𝑎, 𝑐).<br><img src="https://user-images.githubusercontent.com/10709657/59742600-b1632c00-92a0-11e9-8647-a8cb8bbb66b7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59745286-0e61e080-92a7-11e9-9613-25876620d5f3.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59746961-84b41200-92aa-11e9-9f40-d93efe94822f.png" alt="image"><br>书 P18 找到不小于 𝑎 的最小平方数 𝑠^2<br><img src="https://user-images.githubusercontent.com/10709657/59747706-022c5200-92ac-11e9-8387-94f07a767018.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59747967-ac0bde80-92ac-11e9-8d57-9843236d67f8.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59747983-b4641980-92ac-11e9-924d-409e4fb5e097.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59760075-06fd0000-92c4-11e9-838a-be570eab92cc.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59760755-a7075900-92c5-11e9-8131-da852d431c06.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59762067-ea16fb80-92c8-11e9-88ba-77346aab9974.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59763157-8a6e1f80-92cb-11e9-9ae9-17c88f00a0ee.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59764012-68759c80-92cd-11e9-8b11-679f807c65ea.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59764105-a70b5700-92cd-11e9-9312-183d608c1246.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59764978-8e9c3c00-92cf-11e9-9b02-0811e17c6b89.png" alt="image"><br>2.7 这一节有点难。。<br><img src="https://user-images.githubusercontent.com/10709657/59765227-3154ba80-92d0-11e9-982b-b0503f4a7952.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59765803-71686d00-92d1-11e9-947b-cbba6bbfee51.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59766922-d3c26d00-92d3-11e9-8ad5-45f33c3de3b7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59767047-0ff5cd80-92d4-11e9-859d-c0b6371a7580.png" alt="image"></p><p>字母频率：e,t,a<br><img src="https://user-images.githubusercontent.com/10709657/59768187-7aa80880-92d6-11e9-9722-ee4ac8726134.png" alt="image"><br>重合指标注意下标是列优先<br><img src="https://user-images.githubusercontent.com/10709657/59768228-914e5f80-92d6-11e9-85a2-24ba5f6d85d7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59768322-bcd14a00-92d6-11e9-96e0-3abfad2a023a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59768437-f609ba00-92d6-11e9-8e0d-6ea313eccdfa.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59769162-269e2380-92d8-11e9-8040-9cd6d2d3f254.png" alt="image"><br>b 模 n 可逆 iff b 与 n 互质<br><img src="https://user-images.githubusercontent.com/10709657/59778631-733e2a80-92e9-11e9-9974-528cb3307fe6.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59778641-76d1b180-92e9-11e9-92e9-5bb3383e12b4.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59778736-9ec11500-92e9-11e9-90c9-f4f8a13bbe45.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59779905-ada8c700-92eb-11e9-9ac5-a82ecab4e9b5.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59781556-a2a36600-92ee-11e9-83cc-b4e1aa7cb583.png" alt="image"><br>𝑠𝑖 = (𝑣_𝑖 −1)^2 𝑚𝑜𝑑 𝑛<br><img src="https://user-images.githubusercontent.com/10709657/59781748-09288400-92ef-11e9-8197-701ce4772779.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59782440-87d1f100-92f0-11e9-9b90-1c070b532974.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59784408-e9945a00-92f4-11e9-945d-bce04a0ea7a5.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59784411-ec8f4a80-92f4-11e9-8bc5-bbd611c9490c.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59810284-11a4ad00-9337-11e9-9c92-009d8fc99073.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59814233-2426e280-9347-11e9-9185-2d56d2a93e1d.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;初等数论及其应用。。其实有点文科课了。。基本上在背公式。。证明题我是真的没证出来。。tktkddd 轻松秒了&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="数论" scheme="https://ir1d.cf/tags/%E6%95%B0%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>js期末复习</title>
    <link href="https://ir1d.cf/2019/06/21/js%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ir1d.cf/2019/06/21/js期末复习/</id>
    <published>2019-06-21T15:36:49.000Z</published>
    <updated>2019-06-21T15:43:37.189Z</updated>
    
    <content type="html"><![CDATA[<ul><li>[x] <a href="https://github.com/lydiahallie/javascript-questions" target="_blank" rel="noopener">https://github.com/lydiahallie/javascript-questions</a></li></ul><p>JS 好难，之前会的都是皮毛，复习了好多东西。。<br>考完：我复习的都是皮毛。。JS 太神仙了吧</p><a id="more"></a><p>js string immutable<br>toFixed, toPrecision 是四舍五入<br>传的都是引⽤</p><p>箭头函数表达式的语法比函数表达式更简洁，并且没有自己的 this，arguments，super 或 new.target。这些函数表达式更适用于那些本来需要匿名函数的地方，并且它们不能用作构造函数。</p><p><img src="https://user-images.githubusercontent.com/10709657/59082500-fa70c300-8925-11e9-87aa-14b114e7da08.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59082521-0eb4c000-8926-11e9-947a-654feed17732.png" alt="image"></p><p>字符串在声明后，其值就不会再发⽣变化（ immutable）<br>（任何操作都不会改变字符串的值）<br><img src="https://user-images.githubusercontent.com/10709657/59082200-94d00700-8924-11e9-866b-c6e7576ac9e1.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59082319-19228a00-8925-11e9-9d4f-5120f1c2b138.png" alt="image"><br>const 的指向不能变，但是指向的地方的值可以变<br>JS 传引用<br><img src="https://user-images.githubusercontent.com/10709657/59082343-3192a480-8925-11e9-9b12-6fb69f0f4be3.png" alt="image"><br><code>new Array</code> 参数只有一个的时候会被当做是数组里数的个数，而 <code>Array.of(2)</code> 是 <code>[2]</code>，仍为元素值<br><img src="https://user-images.githubusercontent.com/10709657/59082373-6141ac80-8925-11e9-9f9b-7d0c6e7cfd9f.png" alt="image"><br>push 尾，unshift 头；pop 尾，shift 头；pop 和 shift 都会返回被删除的元素<br><code>splice(start, deleteCount, …items)</code>， 如 <code>splice(1, 2, “cat”, “bat”, “pat”)</code><br><code>slice(start, end)</code> 也可用于获取数组的一部分<br>数组是 object，也可添加⾃定义的 property<br><code>.toFixed</code>，<code>.toPrecision</code> 都是四舍五入<br>sort 从小到大: <code>(v1, v2) =&gt; v1 - v2</code><br>函数的 property 可以相当于实现带记忆的函数</p><p>对⼀个 function object 使⽤ typeof 操作符<br>返回 “function”，⽽不是 “object”，但是 function 是 object，可以加 property<br>Symbol 只能作为 function 被调⽤ （也即，调⽤时前⾯不能加 new）<br><img src="https://user-images.githubusercontent.com/10709657/59083042-4886c600-8928-11e9-9f92-5b087c94ebc9.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59083053-5a686900-8928-11e9-977f-7e8b77c86209.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59083064-68b68500-8928-11e9-9d0d-92cb68a71237.png" alt="image"><br>Node.js： global；browser：window<br>若不加 use strict,变量在赋值后会注册成一个全局变量，加了之后不会<br><img src="https://user-images.githubusercontent.com/10709657/59084527-28f29c00-892e-11e9-94f3-0434757a0eef.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59084537-2f811380-892e-11e9-84ff-976b675ecb54.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59086787-598a0400-8935-11e9-89fe-a8c431caf839.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59086957-ec2aa300-8935-11e9-8917-d61bd972772e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59087172-84c12300-8936-11e9-849a-7e1f4b0c05bd.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59087295-d79ada80-8936-11e9-863b-dac6faf309f6.png" alt="image"></p><p>arguments 总是忠实记录着函数调⽤时实际传⼊的参数<br><img src="https://user-images.githubusercontent.com/10709657/59088130-29dcfb00-8939-11e9-9f42-35ea1c4c7345.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59088902-6dd0ff80-893b-11e9-8846-5415f2ff968b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59088919-76293a80-893b-11e9-9669-7c8248f25ff8.png" alt="image"></p><p><code>creature.say_hello.call(cat, 1, 2)</code> 等于 <code>creature.say_hello.apply(dog, [3, 4])</code><br><img src="https://user-images.githubusercontent.com/10709657/59089403-9efdff80-893c-11e9-8454-68fb7b63bd22.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59089417-a58c7700-893c-11e9-8dee-395763a82aa3.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59089361-842b8b00-893c-11e9-9365-17bceeda75bc.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59089696-5561e480-893d-11e9-8d8c-8385e3b636af.png" alt="image"></p><p>函数的 length：参数个数， <strong> 除了 有默认值的 和 rest </strong></p><p>bind 的 args 参数有点相当于是 python 里的 partial，传给函数的前几个参数了<br>main function 里的 <code>this: {}</code>, <code>new.target: undefined</code>, <code>arguments 看起来好像是 cli 的 arguments</code></p><p><img src="https://user-images.githubusercontent.com/10709657/59090054-40398580-893e-11e9-93d5-ccda5f5f0a85.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59090174-a1f9ef80-893e-11e9-903d-d408e9ebbe26.png" alt="image"><br>输出分别是 233 和 undefined。因为在箭头函数生成的时候 this 还没有<br>函数和闭包一一对应：包含 该函数本身、以及在此时可以访问到的所有变量</p><p>Object.getOwnPropertyNames obj.hasOwnProperty 不会去 obj 的原型链上查找<br>in 会顺着原型链找<br>Object.getOwnPropertyNames 找 string 类型的 key，<br>Object.getOwnPropertySymbols 找 symbol 类型</p><p>Object 的 property 的三种默认属性：writable: false, 但必须 use strict 才会不可写<br><img src="https://user-images.githubusercontent.com/10709657/59450076-033c2a00-8e3b-11e9-94ac-c6a10e896201.png" alt="image"><br>读取没有 getter 的 property 返回 undefined<br>在严格模式下 对⼀个没有 setter 的 property 赋值 会触发运⾏时错误<br><img src="https://user-images.githubusercontent.com/10709657/59451697-a2165580-8e3e-11e9-9672-87ee27328d70.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59451748-c2461480-8e3e-11e9-96bd-cb75f78155d6.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59451905-279a0580-8e3f-11e9-89f6-1f901bc9310a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59451913-2d8fe680-8e3f-11e9-9446-6b1426c73e11.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59475218-f809ee00-8e7c-11e9-8825-31294ee7d2eb.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59475393-ca717480-8e7d-11e9-9156-b06980e5fbca.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59475410-ec6af700-8e7d-11e9-8013-b020c33621a5.png" alt="image"><br>for .. in 枚举的是 property （下标），for .. of 枚举的是值<br>for .. of 不改变原来值</p><p>原型链不得有环<br>⼀个通过字⾯量创建的 object 在缺省情况下，其原型链的⻓度是 2<br>⼀个通过字⾯量创建的 function 在缺省情况下，其原型链的⻓度是 3<br><strong>原型链 P358 TODO</strong></p><p><img src="https://user-images.githubusercontent.com/10709657/59476033-60f36500-8e81-11e9-823f-01ea5f8619ea.png" alt="image"><br><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Object_initializer#Computed_property_names" target="_blank" rel="noopener">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Object_initializer#Computed_property_names</a><br><img src="https://user-images.githubusercontent.com/10709657/59476527-ba5c9380-8e83-11e9-8303-954c3f270185.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59476554-db24e900-8e83-11e9-92e7-f24d7a924040.png" alt="image"></p><p>Object.assign(target, source);<br>Object.create(proto, [propertiesObject])<br><img src="https://user-images.githubusercontent.com/10709657/59655331-7b547800-91cc-11e9-8aa1-b250598bca78.png" alt="image"><br>OBject.seal 管的更多<br><img src="https://user-images.githubusercontent.com/10709657/59655942-988a4600-91ce-11e9-99c2-9005851b95c3.png" alt="image"><br>OBject.freeze 管的更更多<br><img src="https://user-images.githubusercontent.com/10709657/59656159-4dbcfe00-91cf-11e9-9e99-08096685fd8b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59656190-5f9ea100-91cf-11e9-9b62-40751e30d889.png" alt="image"><br>用 Object.seal()密封的对象可以改变它们现有的属性。使用 Object.freeze() 冻结的对象中现有属性是不可变的。</p><p><code>Array</code><br>reduce(callbackfn: (previousValue: number, currentValue: number, currentIndex: number, array: number[]) =&gt; number):<br><img src="https://user-images.githubusercontent.com/10709657/59661434-6502e800-91dd-11e9-81b4-b61e05d9e4d5.png" alt="image"><br>Array.prototype.every/some 对于每个元素调用一个 callback 返回一个 bool，通过 every/some 来综合结果<br><img src="https://user-images.githubusercontent.com/10709657/59661540-9e3b5800-91dd-11e9-947b-790438757215.png" alt="image"></p><p>find：查找数组中满⾜给定条件的第⼀个元素<br>如果不存在满⾜给定条件的值，则返回 undefined</p><p><img src="https://user-images.githubusercontent.com/10709657/59661690-ea869800-91dd-11e9-9373-dc023a55187c.png" alt="image"><br><code>Map</code><br><img src="https://user-images.githubusercontent.com/10709657/59661755-1144ce80-91de-11e9-92d8-a92e9c8c8e06.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59662154-ec049000-91de-11e9-9e73-8fb0f9c8b1cd.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59662164-f0c94400-91de-11e9-989c-3af61fa829ec.png" alt="image"></p><p><code>Set</code></p><p>任何⼀个 iterable object 都可以构造成 Set<br><img src="https://user-images.githubusercontent.com/10709657/59662276-3128c200-91df-11e9-8b22-d3b354fe5bae.png" alt="image"></p><p>set 也可以 forEach，但是第三个参数貌似是他自己<br><img src="https://user-images.githubusercontent.com/10709657/59662904-78fc1900-91e0-11e9-8465-32bb4153c821.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59668545-46a3e900-91eb-11e9-9b52-84363be78dea.png" alt="image"><br>嵌套情况<br><img src="https://user-images.githubusercontent.com/10709657/59668964-fb3e0a80-91eb-11e9-837c-114737480530.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59669828-84097600-91ed-11e9-9d06-164bebf22442.png" alt="image"></p><p>rest 是一个数组</p><p><img src="https://user-images.githubusercontent.com/10709657/59670012-c3d05d80-91ed-11e9-8d55-7a8b0b40f8a1.png" alt="image"></p><p><code>【startIndex】</code> 这样之后是解构那个数组的值<br>函数参数里可以直接解构<br><img src="https://user-images.githubusercontent.com/10709657/59670300-4c4efe00-91ee-11e9-84b0-c6be2944a960.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59673346-b3bb7c80-91f3-11e9-9e42-410f5b99f27a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59673352-b7e79a00-91f3-11e9-9ff3-c822acfc6f0e.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59673361-bcac4e00-91f3-11e9-994a-be1dc322ccca.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59673389-ce8df100-91f3-11e9-8eca-39763e157254.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59673620-30e6f180-91f4-11e9-99a5-0d5bd54c10ef.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59681965-c2ac2a00-9207-11e9-9c35-606d7691669a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59681969-c63fb100-9207-11e9-9c7f-05e4539038da.png" alt="image"><br>⼀元操作符 +<br>会将操作数转化为 number 类型的值<br>比如 <code>(+c)</code></p><p>加法的隐式类型转换：<br>先 ToPrimitive，两侧有字符串的话会都转字符串，否则都转 number</p><p>类型转换这章好难。。</p><p><img src="https://user-images.githubusercontent.com/10709657/59683572-fd639180-920a-11e9-9ad2-e3d3236f96bf.png" alt="image"><br>可以自定义转换的方式<br>乘除、减法的话是转 number<br><img src="https://user-images.githubusercontent.com/10709657/59685024-ce9aea80-920d-11e9-827c-ed3155c3ffa2.png" alt="image"><br>left 会隐式转成 bool<br><img src="https://user-images.githubusercontent.com/10709657/59685061-e2dee780-920d-11e9-9a0e-d809550105ca.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59685110-00ac4c80-920e-11e9-9c95-1df2f425fa0a.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59685126-0a35b480-920e-11e9-901a-f378a5a52cb7.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59685146-1457b300-920e-11e9-9344-2875eaec2795.png" alt="image"></p><p><code>所有对象都是像是真的值</code><br>Two distinct objects are never equal for either strict or abstract comparisons.<br>An expression comparing Objects is only true if the operands reference the same Object<br><img src="https://user-images.githubusercontent.com/10709657/59692442-7ff24e00-9217-11e9-9646-d8b1551514d6.png" alt="image"></p><p>Object 的 <code>&lt;=</code> 应该是 ARC 了。。太难了我弃疗了<br>它比 <code>&lt;</code> 会多一个 <code>If r is true or undefined</code>，这个 true 应该就是 arc 比较出来的<br><a href="https://www.ecma-international.org/ecma-262/9.0/index.html#sec-relational-operators-runtime-semantics-evaluation" target="_blank" rel="noopener">https://www.ecma-international.org/ecma-262/9.0/index.html#sec-relational-operators-runtime-semantics-evaluation</a></p><p><img src="https://user-images.githubusercontent.com/10709657/59843833-f1eba400-938b-11e9-9744-ca4d2f1953a4.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59844634-fc0ea200-938d-11e9-8026-a73df0b5c9df.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59844708-21031500-938e-11e9-87ef-bf6077e9e79d.png" alt="image"></p><p>事件对象有⼀个 target 属性<br>其值：事件发⽣在的 HTML 元素<br>事件处理函数（当不是箭头函数时）的 this 参数<br>表示：当前的事件监听函数所附着在的 HTML 元素<br><img src="https://user-images.githubusercontent.com/10709657/59845256-86a3d100-938f-11e9-8017-6361c9860296.png" alt="image"><br>默认是监听冒泡阶段</p><h2 id="在⽗元素上监听⼦元素事件"><a href="#在⽗元素上监听⼦元素事件" class="headerlink" title="在⽗元素上监听⼦元素事件"></a>在⽗元素上监听⼦元素事件</h2><p><img src="https://user-images.githubusercontent.com/10709657/59845673-81935180-9390-11e9-8e4e-b87a8b029dde.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59845890-03837a80-9391-11e9-9983-a90d6b2a5368.png" alt="image"></p><p><img src="https://user-images.githubusercontent.com/10709657/59846812-6f66e280-9393-11e9-97b9-139f76f446cc.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59846822-742b9680-9393-11e9-92b7-f7b09cc9c53b.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59847460-1ac46700-9395-11e9-8e04-097011708988.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59847759-f9b04600-9395-11e9-9e23-7b523ef090f1.png" alt="image"><br>Generator 嵌套<br><img src="https://user-images.githubusercontent.com/10709657/59848150-08e3c380-9397-11e9-9092-29c0bffb267a.png" alt="image"><br>用 generator 实现 DFS<br><img src="https://user-images.githubusercontent.com/10709657/59848389-9aebcc00-9397-11e9-88cc-0625692e3937.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59848403-a212da00-9397-11e9-852c-c7fe7d021c48.png" alt="image"><br>generator 里 return 语句的不会在 for of 里遍历到，只有 yield 出来的会被取到<br>Array.from 的时候也是会忽视 return，尽管实际上这个值也会被放出来，需要手动去取<br><a href="https://stackoverflow.com/a/37202835/4597306" target="_blank" rel="noopener">https://stackoverflow.com/a/37202835/4597306</a><br><img src="https://user-images.githubusercontent.com/10709657/59853076-bc05ea00-93a2-11e9-9b61-1608eae29466.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59853089-c1fbcb00-93a2-11e9-9f91-df181bcefd42.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59853107-cde78d00-93a2-11e9-9e5b-0689b43f2e32.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59853130-d770f500-93a2-11e9-8f90-a2a738aeb54d.png" alt="image"><br>每⼀次在 promise 对象上调⽤ then 或 catch ⽅法<br>都会返回⼀个新的 promise 对象<br>可以在这个新对象上继续调⽤ then 或 catch ⽅法<br><img src="https://user-images.githubusercontent.com/10709657/59853292-2454cb80-93a3-11e9-8b4f-5f907ba434f2.png" alt="image"><br><img src="https://user-images.githubusercontent.com/10709657/59854405-726ace80-93a5-11e9-998f-ab294b6b734b.png" alt="image"><br>![image](<a href="https://user-images.githubusercontent.com/10709657/59854740-0f2d6c00-93a6-11e9-8e5a-7d6de74a" target="_blank" rel="noopener">https://user-images.githubusercontent.com/10709657/59854740-0f2d6c00-93a6-11e9-8e5a-7d6de74a</a><br>使用 var 关键字，你可以用相同的名称声明多个变量。然后变量将保存最新的值。</p><p>你不能使用 let 或 const 来实现这一点，因为它们是块作用域的。</p><p>所有对象的键（不包括 Symbol）在底层都是字符串，即使你自己没有将其作为字符串输入。</p><p>obj 如果你有两个名称相同的键，则键会被替换掉。它仍然位于第一个键出现的位置，但是值是最后出现那个键的值。</p><p>对象的键被自动转换为字符串<br>当字符串化一个对象时，它会变成 “[Object object]”<br><img src="https://user-images.githubusercontent.com/10709657/59862974-676c6a00-93b6-11e9-9012-8e7c1a159011.png" alt="image"></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;[x] &lt;a href=&quot;https://github.com/lydiahallie/javascript-questions&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/lydiahallie/javascript-questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;JS 好难，之前会的都是皮毛，复习了好多东西。。&lt;br&gt;考完：我复习的都是皮毛。。JS 太神仙了吧&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="JS" scheme="https://ir1d.cf/tags/JS/"/>
    
  </entry>
  
  <entry>
    <title>FastAI踩坑</title>
    <link href="https://ir1d.cf/2019/05/05/FastAI%E8%B8%A9%E5%9D%91/"/>
    <id>https://ir1d.cf/2019/05/05/FastAI踩坑/</id>
    <published>2019-05-04T16:09:24.000Z</published>
    <updated>2019-05-04T16:32:59.511Z</updated>
    
    <content type="html"><![CDATA[<ul><li>五一一直在调 Fast.AI</li></ul><a id="more"></a><p>训 SSD 的时候遇到了灵异事件，</p><p>遇到了个似乎问题差不多的老哥 <a href="https://stackoverflow.com/questions/48595240/map-decreasing-with-training-tensorflow-object-detection-ssd" target="_blank" rel="noopener">https://stackoverflow.com/questions/48595240/map-decreasing-with-training-tensorflow-object-detection-ssd</a> 但是我调了它说的这个参数，并没有什么效果。然后我发现同样的 model，用 pytorch 有这个问题，但是封进 fastai 的版本就没有这个毛病。</p><p>然后由于不满足与只 train 不 valid，然后加了 validation，然后就进入了 6h 一个 epoch 然后发现 valid 炸了的状态，后来发帖才知道可以 <code>learn.validate()</code> （然而这个函数对数据的 type 也有一些奇怪的隐含要求.. doc 写得不太清楚）</p><p>哦读入的时候也很坑，搞了好久那个 databunch，因为看它 doc 里写说什么如果用 pytorch 的 vanilla dataset，有些 fastai 的函数不滋兹（x然而后来也没用上）。用的那个 <code>ObjectItemList</code>，然后它 <code>get_label_from_func</code> 之后竟然会把 bounding box 的坐标给 norm 成 [-1,1] 之间的.. 然后我转成 [0..1] 的时候又翻车了一万次.. 因为我之前搞成一个 list 就可以，但是 fastai 它不爽，要用个 <code>bb_pad_collate</code> 给封成一个 torch tensor= =</p><p>其实 doc 里有写.. 但我总是之后才找到..</p><p>然后有个坑是那个 ImageBBox 的坐标默认顺序是 <code>(top, left, bottom, right)</code>，和我之前的也不一样= =，然后就翻车了.. 倒也没炸掉，只是 loss 奇高，but really time consuming</p><p>现在能顺利 run 起来了，除了偶尔它莫名其妙 out of memory （也可能是服务器上别的 process 搞得，说不好）以外没啥毛病（#flag）</p><p>这几天在 forum 开了一万个帖子.. 感觉自己太 push 了（（</p><p>可是 fastai 的文档看着是真的不舒服.. 习惯了 pytorch 那种简明扼要 example 充足的..</p><p>fastai 的东西封装得很细，但是不会用就只能炸炸炸..</p><p>惨惨 QAQ</p><p>我记得好像还没有用 FastAI 写 Object Detection 的指南，如果有空可以整理一下 code（</p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;五一一直在调 Fast.AI&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="pytorch" scheme="https://ir1d.cf/tags/pytorch/"/>
    
      <category term="Fast.AI" scheme="https://ir1d.cf/tags/Fast-AI/"/>
    
  </entry>
  
  <entry>
    <title>groupsNotes-0424</title>
    <link href="https://ir1d.cf/2019/04/24/groupsNotes-0424/"/>
    <id>https://ir1d.cf/2019/04/24/groupsNotes-0424/</id>
    <published>2019-04-24T11:51:56.000Z</published>
    <updated>2019-04-24T16:31:40.245Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><ul><li><a href="https://arxiv.org/pdf/1904.04971.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.04971.pdf</a> <ul><li>Soft Conditional Computation</li><li>这个挺有意思的，感觉最近这种dynamic network的工作很多</li></ul></li><li>cv里梯度一般是 1e-3 - 1e-8<ul><li>很少task用adam</li><li>大部分就momentum</li><li>一些生成模型用adam，还有一些pipeline较长的用</li><li>比如image classification呢 ? sgd</li><li>Detection,segmentation 都 sgd加momentum</li><li>Adam 泛化差</li><li>adam在gradient sparse时有很大优势，所以很多nlp task常用 （在同一次梯度反向传播的时候很多参数梯度很小或者都是0？）</li><li>噢噢，要是有空我讲讲Bengio的一篇文章，关于unsupervised pre-train影响的</li><li>对任意模型架构，通过P(X)去无监督学任意层的初始化表达</li><li><a href="http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf" target="_blank" rel="noopener">http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf</a></li><li>Unsupervised Feature Learning via Non-Parametric Instance Discrimination</li></ul></li><li><a href="http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0801.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0801.pdf</a><ul><li>去年cvpr的一篇文章，idea挺简单也挺有意思的。通过instance-wise discrimination学到的feature做classification。</li></ul></li><li><a href="https://arxiv.org/pdf/1904.10281.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1904.10281.pdf</a></li><li><p><strong>Dynamic network</strong></p><ul><li><strong>weight prediction</strong></li><li>training loss 可以降，但是泛化效果没有 gain</li></ul></li><li><p>A series of paper from sensetime</p><ul><li><a href="https://arxiv.org/abs/1904.09739" target="_blank" rel="noopener">https://arxiv.org/abs/1904.09739</a></li><li>Switchable Whitening for Deep Representation Learning</li><li><a href="https://arxiv.org/abs/1807.09441" target="_blank" rel="noopener">https://arxiv.org/abs/1807.09441</a></li><li>Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net</li><li><a href="https://arxiv.org/abs/1806.10779" target="_blank" rel="noopener">https://arxiv.org/abs/1806.10779</a></li><li>Differentiable Learning-to-Normalize via Switchable Normalization</li><li><a href="https://arxiv.org/abs/1609.09106" target="_blank" rel="noopener">https://arxiv.org/abs/1609.09106</a></li></ul></li><li><p>HyperNetworks</p><ul><li>Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve near state-of-the-art results on a variety of sequence modelling tasks</li></ul></li><li><p>FaceNet: A Unified Embedding for Face Recognition and Clustering</p><ul><li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf" target="_blank" rel="noopener">https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Schroff_FaceNet_A_Unified_2015_CVPR_paper.pdf</a></li></ul></li><li>Unsupervised Feature Learning via Non-Parametric Instance Discrimination<ul><li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf</a></li></ul></li><li>A Bottom-up Clustering Approach to Unsupervised Person Re-identification<ul><li><a href="http://xuanyidong.com/pdf/AAAI19-vana.pdf" target="_blank" rel="noopener">http://xuanyidong.com/pdf/AAAI19-vana.pdf</a></li></ul></li><li>Learning Deep Embeddings with Histogram Loss<ul><li><a href="http://papers.nips.cc/paper/6463-learning-deep-embeddings-with-histogram-loss" target="_blank" rel="noopener">http://papers.nips.cc/paper/6463-learning-deep-embeddings-with-histogram-loss</a></li></ul></li></ul><p>我觉得我今晚完全掉线了.. 急需好好补习一下..</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1904.04971.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1904.04971.pd
      
    
    </summary>
    
      <category term="paperReading" scheme="https://ir1d.cf/categories/paperReading/"/>
    
    
      <category term="paperReading" scheme="https://ir1d.cf/tags/paperReading/"/>
    
  </entry>
  
  <entry>
    <title>代组期中笔记</title>
    <link href="https://ir1d.cf/2019/04/24/%E4%BB%A3%E7%BB%84%E6%9C%9F%E4%B8%AD%E7%AC%94%E8%AE%B0/"/>
    <id>https://ir1d.cf/2019/04/24/代组期中笔记/</id>
    <published>2019-04-24T07:53:22.000Z</published>
    <updated>2019-04-24T08:02:23.761Z</updated>
    
    <content type="html"><![CDATA[<p>本来以为会特别硬核.. 一直在抢救证明题.. 结果最后一堆算实例.. gggg</p><p>在群同态基本定理上建立的知识体系.. 却想不清楚它本身是怎么证明的了.. QAQ</p><p>熬夜抢救考试之后突击测 12 分钟跑简直要了命了.. 这么个阴天也能晒伤我真是服了= =</p><a id="more"></a><p>Ir1d XD+, [21.04.19 22:36]<br>子群判定定理<br>子群格</p><p>Ir1d XD+, [22.04.19 14:44]<br>同态的表示形式<br>群同态定理</p><p>Ir1d XD+, [22.04.19 20:24]<br>置换之积 从右向左</p><p><img src="https://i.loli.net/2019/04/24/5cc0165ec623a.png" alt="20190424155509.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016626b4d2.png" alt="20190424155513.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01666c4f40.png" alt="20190424155517.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0166a51296.png" alt="20190424155521.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0166f9c76a.png" alt="20190424155525.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01682210af.png" alt="20190424155544.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016865d6f6.png" alt="20190424155549.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01689cc3f6.png" alt="20190424155552.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0168d3af9b.png" alt="20190424155556.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016927f18e.png" alt="20190424155559.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016951fc90.png" alt="20190424155604.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016989fbe3.png" alt="20190424155607.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0169b9a5bc.png" alt="20190424155610.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0169f7caed.png" alt="20190424155613.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016a42b2b5.png" alt="20190424155618.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016a7a1c18.png" alt="20190424155621.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016abc53fd.png" alt="20190424155626.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016af2b3d9.png" alt="20190424155629.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016b2d4eb9.png" alt="20190424155633.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016dd8294b.png" alt="20190424155715.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016ba9b73f.png" alt="20190424155641.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016e599a0c.png" alt="20190424155724.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016e913680.png" alt="20190424155727.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016ec7f110.png" alt="20190424155731.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc016f6cdd72.png" alt="20190424155741.png"></p><p>于是期中就考完了吧.. 冷静分析一下其实这学期一直在翘课，期中复习得也很仓促.. 中间病得很厉害.. 然后是不是还有 challenge 翻车需要背锅.. 就很僵硬.. 下半学期也好不到哪里去吧.. 一万个大作业.. 三个 kaggle.. 然后还有 4 个 pre.. 一篇综述.. 希望期末可以认认真真地认认真真..</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本来以为会特别硬核.. 一直在抢救证明题.. 结果最后一堆算实例.. gggg&lt;/p&gt;
&lt;p&gt;在群同态基本定理上建立的知识体系.. 却想不清楚它本身是怎么证明的了.. QAQ&lt;/p&gt;
&lt;p&gt;熬夜抢救考试之后突击测 12 分钟跑简直要了命了.. 这么个阴天也能晒伤我真是服了= =&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="代数结构" scheme="https://ir1d.cf/tags/%E4%BB%A3%E6%95%B0%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>概统期中笔记</title>
    <link href="https://ir1d.cf/2019/04/24/%E6%A6%82%E7%BB%9F%E6%9C%9F%E4%B8%AD%E7%AC%94%E8%AE%B0/"/>
    <id>https://ir1d.cf/2019/04/24/概统期中笔记/</id>
    <published>2019-04-24T07:48:40.000Z</published>
    <updated>2019-04-24T07:53:04.382Z</updated>
    
    <content type="html"><![CDATA[<p>我发现上回整理了这个 post 的模板之后根本就没写过 post.. gg</p><p>概统这波.. 讲道理没什么难度的.. 是我送了</p><a id="more"></a><p><img src="https://i.loli.net/2019/04/24/5cc0152fa8789.png" alt="20190424155005.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0154722af5.png" alt="20190424155029.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0154e5352e.png" alt="20190424155037.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01553b4472.png" alt="20190424155042.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0155a035d9.png" alt="20190424155048.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0156b0dd4b.png" alt="20190424155106.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01570610a6.png" alt="20190424155111.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01576523c5.png" alt="20190424155117.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc0157cb663e.png" alt="20190424155123.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc015810c873.png" alt="20190424155127.png"></p><p><img src="https://i.loli.net/2019/04/24/5cc01587600cb.png" alt="20190424155134.png"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我发现上回整理了这个 post 的模板之后根本就没写过 post.. gg&lt;/p&gt;
&lt;p&gt;概统这波.. 讲道理没什么难度的.. 是我送了&lt;/p&gt;
    
    </summary>
    
      <category term="笔记" scheme="https://ir1d.cf/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="概率统计" scheme="https://ir1d.cf/tags/%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1/"/>
    
  </entry>
  
</feed>
